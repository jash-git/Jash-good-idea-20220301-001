7大經典回歸模型總結

資料來源: https://mp.weixin.qq.com/s/z4gWtLxmFgIbh1qFGp9-zQ

 1.Linear Regression 線性回歸
    要點：
    1.自變量與因變量之間必須有線性關係
    2.多元回歸存在多重共線性，自相關性和異方差性。
    3.線性回歸對異常值非常敏感。它會嚴重影響回歸線，最終影響預測值。
    4.多重共線性會增加係數估計值的方差，使得在模型輕微變化下，估計非常敏感。結果就是係數估計值不穩定
    5.在多個自變量的情況下，我們可以使用向前選擇法，向後剔除法和逐步篩選法來選擇最重要的自變量。 
 2.Logistic Regression 邏輯回歸
    要點：
    1.它廣泛的用於分類問題。
    2.邏輯回歸不要求自變量和因變量是線性關係。它可以處理各種類型的關係，因為它對預測的相對風險指數OR使用了一個非線性的log轉換。
    3.為了避免過擬合和欠擬合，我們應該包括所有重要的變量。有一個很好的方法來確保這種情況，就是使用逐步篩選方法來估計邏輯回歸。
    4.它需要大的樣本量，因為在樣本數量較少的情況下，極大似然估計的效果比普通的最小二乘法差。
    5.自變量不應該相互關聯的，即不具有多重共線性。然而，在分析和建模中，我們可以選擇包含分類變量相互作用的影響。
    6.如果因變量的值是定序變量，則稱它為序邏輯回歸。
    7.如果因變量是多類的話，則稱它為多元邏輯回歸。 
 3.Polynomial Regression 多項式回歸
    重點：
    雖然會有一個誘導可以擬合一個高次多項式並得到較低的錯誤，但這可能會導致過擬合。你需要經常畫出關係圖來查看擬合情況，並且專注於保證擬合合理，既沒有過擬合又沒有欠擬合。 
 4.Stepwise Regression 逐步回歸 
 5.Ridge Regression嶺回歸
    要點：
    1.除常數項以外，這種回歸的假設與最小二乘回歸類似；
    2.它收縮了相關係數的值，但沒有達到零，這表明它沒有特徵選擇功能
    3.這是一個正則化方法，並且使用的是L2正則化。 
 6.Lasso Regression套索回歸
    要點：
    1.除常數項以外，這種回歸的假設與最小二乘回歸類似；
    2.它收縮係數接近零（等於零），這確實有助於特徵選擇；
    3.這是一個正則化方法，使用的是L1正則化；
    如果預測的一組變量是高度相關的，Lasso 會選出其中一個變量並且將其它的收縮為零。 
 7.ElasticNet回歸
    要點：
    1.在高度相關變量的情況下，它會產生群體效應；
    2.選擇變量的數目沒有限制；
    3.它可以承受雙重收縮。 